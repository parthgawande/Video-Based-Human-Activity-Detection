# üìπ Video-Based Human Activity Detection

This repository is dedicated to the research paper **"Video-Based Human Activity Detection"**, which focuses on the detection and recognition of human activities in video using convolutional neural networks (CNNs) and incremental learning techniques. The paper presents an innovative system that processes video data to classify human actions with high accuracy, addressing challenges in computer vision and surveillance systems.

---

## üîó Research Paper Link

You can access the full research paper here: [Video-Based Human Activity Detection](https://ieeexplore.ieee.org/document/9847958)

---

## üìú Abstract

With the exponential growth of video data generated by surveillance cameras, there is a pressing need to analyze this data for detecting human activities. This research proposes a system that utilizes **Convolutional Neural Networks (CNN)** with **incremental learning** to detect human activities in videos. The system processes video data from the **KTH dataset**, which includes various actions such as walking, jogging, running, and more. The proposed method enhances the accuracy of human activity detection by addressing issues such as changing backgrounds, occlusions, and performer variability.

### Key Contributions:
- **Incremental Learning**: The model continuously updates with new video data while retaining previously learned knowledge, thus avoiding catastrophic forgetting.
- **Action Recognition**: The system classifies six different human actions: walking, jogging, running, boxing, hand clapping, and hand waving.
- **Benchmark Dataset**: The model was trained and tested on the **KTH dataset**, achieving a high accuracy rate.

---

## üß† Methodology

The system architecture is divided into three main components:
1. **Data Collection and Preprocessing**:
   - Video data is collected from the KTH dataset, which consists of six types of human actions.
   - Preprocessing involves extracting frames from the video and converting them into a format suitable for input into the CNN model.
   
2. **Model Engine and Performance Tuning**:
   - The **3D Convolutional Neural Network (CNN)** is used for feature extraction and classification.
   - Incremental learning techniques are applied to allow the system to learn new examples without losing previously acquired knowledge. Checkpoints are used to retrain the model efficiently.
   
3. **Model Output**:
   - The system provides real-time classification of human activities, displayed through a user interface.
   - The proposed system achieved a high accuracy rate of **98.88%** on the KTH dataset, outperforming state-of-the-art methods.

---

## üìä Experimental Results

The model was trained and evaluated using several metrics:
- **Accuracy**: The system achieved an overall accuracy of **98.88%** on the KTH dataset.
- **Precision and F-Score**: Class-wise evaluation showed that all six classes, except for running, achieved accuracy rates above 90%. The running class achieved an accuracy of **81.18%**.
- **Comparative Performance**: The proposed system outperformed several existing methods for human activity detection, including those using SVM classifiers, Long-Term Temporal Convolutions, and adaptive neural networks.

---

## üõ†Ô∏è Tools & Technologies

| Tool/Technology  | Description  |
| ---------------- | ------------ |
| ![Python](https://img.shields.io/badge/-Python-3776AB?logo=python&logoColor=white) | Programming language used for data processing and model implementation. |
| ![Keras](https://img.shields.io/badge/-Keras-D00000?logo=keras&logoColor=white) | Used for building and training the Convolutional Neural Networks. |
| ![TensorFlow](https://img.shields.io/badge/-TensorFlow-FF6F00?logo=tensorflow&logoColor=white) | Backend for deep learning model execution and incremental learning. |
| ![Jupyter](https://img.shields.io/badge/-Jupyter-orange?logo=jupyter&logoColor=white) | For documenting and executing the data analysis and model training process. |
| **KTH Dataset** | A benchmark dataset for human action recognition. |

---

## üìà Performance Evaluation

The proposed system was evaluated using multiple performance metrics:
- **Class-wise Evaluation**: The system performed exceptionally well for activities such as walking, boxing, and hand waving, with accuracy rates over 90%. The running activity posed a challenge, with a slightly lower accuracy of 81.18%.
- **Model Comparison**: The system was benchmarked against other state-of-the-art methods in human action recognition, outperforming models such as Long-Term Temporal Convolutions and adaptive LSTM networks.
  
   **Graphical performance evaluations** of accuracy and precision for each class were visualized, demonstrating significant improvement over previous approaches.

---

## üîÆ Future Scope

- **Integration with Real-Time Video Surveillance**: The proposed system can be extended for real-time surveillance applications, providing human activity recognition in live video streams.
- **Extended Action Classes**: The system can be expanded to recognize a broader range of human activities beyond the six classes included in the KTH dataset.
- **Improved Performance for Running Class**: Further tuning of the model could improve the accuracy for more challenging actions such as running.
- **Multi-person Activity Detection**: Extending the model to detect and analyze interactions between multiple individuals in videos.

---

## ‚ú® Contributors

- **Vandana Japtap** ‚Äì [MIT-WPU, Pune](mailto:vandana.jagtap@mitwpu.edu.in)
- **Parth Gawande** ‚Äì [MIT-WPU, Pune](mailto:parthgawande2000@gmail.com)
- **Yash Rathore** ‚Äì [MIT-WPU, Pune](mailto:yashrathore02061999@gmail.com)
- **Aditya Rao** ‚Äì [MIT-WPU, Pune](mailto:aditya.rao1890@gmail.com)
- **Sarthak Oke** ‚Äì [MIT-WPU, Pune](mailto:sarthakoke@gmail.com)
- **Prerna Didwania** ‚Äì [MIT-WPU, Pune](mailto:prerna.didwania@gmail.com)


